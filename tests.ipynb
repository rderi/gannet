{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation import Generation\n",
    "from evolution_parameters import EvolutionParameters\n",
    "from genome_parameters import GenomeParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_cnt = 100\n",
    "mutation_prob = 0.3\n",
    "crossover_prob = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EvolutionParameters.__init__() missing 4 required positional arguments: 'training_data', 'test_data', 'loss_fn', and 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m generation \u001b[39m=\u001b[39m Generation(population_cnt, \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                  EvolutionParameters(mutation_prob, crossover_prob), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                  GenomeParameters(max_hidden_layers\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: EvolutionParameters.__init__() missing 4 required positional arguments: 'training_data', 'test_data', 'loss_fn', and 'optimizer'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "generation = Generation(population_cnt, \n",
    "                 EvolutionParameters(mutation_prob, crossover_prob), \n",
    "                 GenomeParameters(max_hidden_layers=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'mps',\n",
       " 'population_cnt': 100,\n",
       " 'evolution_params': <evolution_parameters.EvolutionParameters at 0x28ad41430>,\n",
       " 'genome_params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'population': [<individual.Individual at 0x28aff1370>,\n",
       "  <individual.Individual at 0x28a48c3b0>,\n",
       "  <individual.Individual at 0x28aff1be0>,\n",
       "  <individual.Individual at 0x28aff12e0>,\n",
       "  <individual.Individual at 0x28aff1940>,\n",
       "  <individual.Individual at 0x28aff0470>,\n",
       "  <individual.Individual at 0x28aff01d0>,\n",
       "  <individual.Individual at 0x28aff05c0>,\n",
       "  <individual.Individual at 0x28aff04d0>,\n",
       "  <individual.Individual at 0x28aff0200>,\n",
       "  <individual.Individual at 0x28aff00b0>,\n",
       "  <individual.Individual at 0x28aff0590>,\n",
       "  <individual.Individual at 0x28aff0350>,\n",
       "  <individual.Individual at 0x28aff15e0>,\n",
       "  <individual.Individual at 0x28aff0530>,\n",
       "  <individual.Individual at 0x28aff0320>,\n",
       "  <individual.Individual at 0x28aff0800>,\n",
       "  <individual.Individual at 0x28aff06e0>,\n",
       "  <individual.Individual at 0x28aff0620>,\n",
       "  <individual.Individual at 0x28aff0740>,\n",
       "  <individual.Individual at 0x28aff0b90>,\n",
       "  <individual.Individual at 0x28aff0ad0>,\n",
       "  <individual.Individual at 0x28aff0290>,\n",
       "  <individual.Individual at 0x28aff07d0>,\n",
       "  <individual.Individual at 0x28aff0950>,\n",
       "  <individual.Individual at 0x28aff0e00>,\n",
       "  <individual.Individual at 0x28aff0c50>,\n",
       "  <individual.Individual at 0x28aff0890>,\n",
       "  <individual.Individual at 0x28aff2ae0>,\n",
       "  <individual.Individual at 0x28aff1a00>,\n",
       "  <individual.Individual at 0x28aff1b20>,\n",
       "  <individual.Individual at 0x28aff29c0>,\n",
       "  <individual.Individual at 0x28aff0b30>,\n",
       "  <individual.Individual at 0x28aff2d50>,\n",
       "  <individual.Individual at 0x28aff2e70>,\n",
       "  <individual.Individual at 0x28aff2480>,\n",
       "  <individual.Individual at 0x28aff2c30>,\n",
       "  <individual.Individual at 0x28aff2f00>,\n",
       "  <individual.Individual at 0x28aff2f90>,\n",
       "  <individual.Individual at 0x28aff2f30>,\n",
       "  <individual.Individual at 0x28aff3020>,\n",
       "  <individual.Individual at 0x28aff2ff0>,\n",
       "  <individual.Individual at 0x28aff30b0>,\n",
       "  <individual.Individual at 0x28aff3650>,\n",
       "  <individual.Individual at 0x28aff37a0>,\n",
       "  <individual.Individual at 0x28aff31a0>,\n",
       "  <individual.Individual at 0x28aff3740>,\n",
       "  <individual.Individual at 0x28aff3410>,\n",
       "  <individual.Individual at 0x28aff2fc0>,\n",
       "  <individual.Individual at 0x28aff3200>,\n",
       "  <individual.Individual at 0x28aff38f0>,\n",
       "  <individual.Individual at 0x28aff3590>,\n",
       "  <individual.Individual at 0x28aff3440>,\n",
       "  <individual.Individual at 0x28aff2cf0>,\n",
       "  <individual.Individual at 0x28aff3b30>,\n",
       "  <individual.Individual at 0x28aff3ad0>,\n",
       "  <individual.Individual at 0x28aff3a10>,\n",
       "  <individual.Individual at 0x28aff39e0>,\n",
       "  <individual.Individual at 0x28aff3b00>,\n",
       "  <individual.Individual at 0x28aff1bb0>,\n",
       "  <individual.Individual at 0x28aff1c40>,\n",
       "  <individual.Individual at 0x28aff1a30>,\n",
       "  <individual.Individual at 0x28aff1b50>,\n",
       "  <individual.Individual at 0x28aff1e80>,\n",
       "  <individual.Individual at 0x28aff1c10>,\n",
       "  <individual.Individual at 0x28aff1eb0>,\n",
       "  <individual.Individual at 0x28aff1df0>,\n",
       "  <individual.Individual at 0x28aff2060>,\n",
       "  <individual.Individual at 0x28aff2210>,\n",
       "  <individual.Individual at 0x28aff1f10>,\n",
       "  <individual.Individual at 0x28aff2030>,\n",
       "  <individual.Individual at 0x28aff2150>,\n",
       "  <individual.Individual at 0x28aff22a0>,\n",
       "  <individual.Individual at 0x28aff2270>,\n",
       "  <individual.Individual at 0x28aff23f0>,\n",
       "  <individual.Individual at 0x28aff2390>,\n",
       "  <individual.Individual at 0x28aff23c0>,\n",
       "  <individual.Individual at 0x28aff1730>,\n",
       "  <individual.Individual at 0x28aff20f0>,\n",
       "  <individual.Individual at 0x28aff2600>,\n",
       "  <individual.Individual at 0x28aff2720>,\n",
       "  <individual.Individual at 0x28aff2780>,\n",
       "  <individual.Individual at 0x28aff2930>,\n",
       "  <individual.Individual at 0x28aff2960>,\n",
       "  <individual.Individual at 0x28aff28a0>,\n",
       "  <individual.Individual at 0x28aff0ef0>,\n",
       "  <individual.Individual at 0x28aff3980>,\n",
       "  <individual.Individual at 0x28aff31d0>,\n",
       "  <individual.Individual at 0x28aff33e0>,\n",
       "  <individual.Individual at 0x28b8d84a0>,\n",
       "  <individual.Individual at 0x28b8d81d0>,\n",
       "  <individual.Individual at 0x28b8d8290>,\n",
       "  <individual.Individual at 0x28b8d82c0>,\n",
       "  <individual.Individual at 0x28b8d8230>,\n",
       "  <individual.Individual at 0x28b8d8440>,\n",
       "  <individual.Individual at 0x28b8d8770>,\n",
       "  <individual.Individual at 0x28b8d88c0>,\n",
       "  <individual.Individual at 0x28b8d8950>,\n",
       "  <individual.Individual at 0x28b8d87d0>,\n",
       "  <individual.Individual at 0x28b8d8860>]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genome': <genomes.Genome at 0x28aff2180>,\n",
       " 'evolution_params': <evolution_parameters.EvolutionParameters at 0x28ad41430>,\n",
       " 'genome_params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'device': 'mps'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = generation.population[random.randint(0, generation.population_cnt -1)]\n",
    "vars(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'epochs': 44,\n",
       " 'batch_size': 69,\n",
       " 'hidden_layers': 3,\n",
       " 'activation_fns': [torch.nn.modules.linear.Linear,\n",
       "  torch.nn.modules.activation.Softmax,\n",
       "  torch.nn.modules.activation.Softmax],\n",
       " 'neuron_cnt': array([86, 99, 99])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome = ind.genome\n",
    "vars(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m): ind\u001b[39m.\u001b[39mmutate()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/individual.py:24\u001b[0m, in \u001b[0;36mIndividual.mutate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmutate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Mutate the individual with a given probability\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m       TODO: extend if new mutation functions are added'''\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     Mutation\u001b[39m.\u001b[39;49mrandom_resetting(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevolution_params\u001b[39m.\u001b[39;49mmutation_probability)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/mutation.py:26\u001b[0m, in \u001b[0;36mMutation.random_resetting\u001b[0;34m(individual, probability)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39melif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mactivation_fns\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     25\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, genome\u001b[39m.\u001b[39mhidden_layers)\n\u001b[0;32m---> 26\u001b[0m     genome\u001b[39m.\u001b[39;49mactivation_fns[idx] \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(params\u001b[39m.\u001b[39mactivation_functions)\n\u001b[1;32m     27\u001b[0m \u001b[39melif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneuron_cnt\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     28\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, genome\u001b[39m.\u001b[39mhidden_layers)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "for _ in range(5): ind.mutate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'epochs': 33,\n",
       " 'batch_size': 39,\n",
       " 'hidden_layers': 6,\n",
       " 'activation_fns': array([<class 'torch.nn.modules.linear.Linear'>], dtype=object),\n",
       " 'neuron_cnt': array([12])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome = ind.genome\n",
    "vars(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossover import Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.choice(generation.population, 2, replace=False)\n",
    "ind1 = inds[0]\n",
    "ind2 = inds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'epochs': 4,\n",
       " 'batch_size': 68,\n",
       " 'hidden_layers': 8,\n",
       " 'activation_fns': [torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.Softmax,\n",
       "  torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.GELU,\n",
       "  torch.nn.modules.activation.PReLU,\n",
       "  torch.nn.modules.activation.GELU,\n",
       "  torch.nn.modules.linear.Linear],\n",
       " 'neuron_cnt': array([22, 22, 22, 22, 22, 22, 22, 22])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(ind1.genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': <genome_parameters.GenomeParameters at 0x28aff1430>,\n",
       " 'epochs': 21,\n",
       " 'batch_size': 19,\n",
       " 'hidden_layers': 8,\n",
       " 'activation_fns': [torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.Softmin,\n",
       "  torch.nn.modules.activation.Tanh,\n",
       "  torch.nn.modules.activation.Softmin,\n",
       "  torch.nn.modules.activation.Tanh,\n",
       "  torch.nn.modules.activation.Tanh,\n",
       "  torch.nn.modules.activation.PReLU,\n",
       "  torch.nn.modules.activation.LeakyReLU],\n",
       " 'neuron_cnt': array([5, 5, 5, 5, 5, 5, 5, 5])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(ind2.genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': <genome_parameters.GenomeParameters at 0x28bd185c0>,\n",
       " 'epochs': 21,\n",
       " 'batch_size': 68,\n",
       " 'hidden_layers': 8,\n",
       " 'activation_fns': [torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.Softmax,\n",
       "  torch.nn.modules.activation.Hardswish,\n",
       "  torch.nn.modules.activation.GELU,\n",
       "  torch.nn.modules.activation.PReLU,\n",
       "  torch.nn.modules.activation.GELU,\n",
       "  torch.nn.modules.linear.Linear],\n",
       " 'neuron_cnt': array([5, 5, 5, 5, 5, 5, 5, 5])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind3 = ind1.crossover(ind2)\n",
    "vars(ind3.genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from individual import Individual\n",
    "from neural_network import NeuralNetwork\n",
    "from fitness import FitnessEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EvolutionParameters.__init__() missing 4 required positional arguments: 'training_data', 'test_data', 'loss_fn', and 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ind \u001b[39m=\u001b[39m Individual(EvolutionParameters(mutation_prob, crossover_prob), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                             GenomeParameters(\u001b[39m#activation_functions=[torch.nn.Linear, torch.nn.ReLU],\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                              \u001b[39m#min_epochs=10, max_epochs=10,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                              min_hidden_neurons\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, max_hidden_neurons\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                              ),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mvars\u001b[39m(ind\u001b[39m.\u001b[39mgenome)\n",
      "\u001b[0;31mTypeError\u001b[0m: EvolutionParameters.__init__() missing 4 required positional arguments: 'training_data', 'test_data', 'loss_fn', and 'optimizer'"
     ]
    }
   ],
   "source": [
    "ind = Individual(EvolutionParameters(mutation_prob, crossover_prob), \n",
    "                            GenomeParameters(#activation_functions=[torch.nn.Linear, torch.nn.ReLU],\n",
    "                                             #min_epochs=10, max_epochs=10,\n",
    "                                             min_hidden_neurons=256, max_hidden_neurons=1024\n",
    "                                             ),\n",
    "                            device='mps')\n",
    "vars(ind.genome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (model): Sequential(\n",
       "    (input): Linear(in_features=784, out_features=1008, bias=True)\n",
       "    (ELU0): ELU(alpha=1.0)\n",
       "    (Sigmoid0): Sigmoid()\n",
       "    (LeakyReLU0): LeakyReLU(negative_slope=0.01)\n",
       "    (PReLU0): PReLU(num_parameters=1)\n",
       "    (SELU0): SELU()\n",
       "    (ELU1): ELU(alpha=1.0)\n",
       "    (Softmin0): Softmin(dim=None)\n",
       "    (Hardswish0): Hardswish()\n",
       "    (Softmax0): Softmax(dim=None)\n",
       "    (Softmin1): Softmin(dim=None)\n",
       "    (Sigmoid1): Sigmoid()\n",
       "    (GELU0): GELU(approximate='none')\n",
       "    (PReLU1): PReLU(num_parameters=1)\n",
       "    (Sigmoid2): Sigmoid()\n",
       "    (ReLU0): ReLU()\n",
       "    (GELU1): GELU(approximate='none')\n",
       "    (Sigmoid3): Sigmoid()\n",
       "    (GELU2): GELU(approximate='none')\n",
       "    (GELU3): GELU(approximate='none')\n",
       "    (Softmin2): Softmin(dim=None)\n",
       "    (GELU4): GELU(approximate='none')\n",
       "    (ReLU1): ReLU()\n",
       "    (Softmax1): Softmax(dim=None)\n",
       "    (SELU1): SELU()\n",
       "    (SELU2): SELU()\n",
       "    (GELU5): GELU(approximate='none')\n",
       "    (Sigmoid4): Sigmoid()\n",
       "    (PReLU2): PReLU(num_parameters=1)\n",
       "    (ELU2): ELU(alpha=1.0)\n",
       "    (SELU3): SELU()\n",
       "    (Linear0): Linear(in_features=1008, out_features=823, bias=True)\n",
       "    (Tanh0): Tanh()\n",
       "    (Softmax2): Softmax(dim=None)\n",
       "    (ReLU2): ReLU()\n",
       "    (Softmin3): Softmin(dim=None)\n",
       "    (ReLU3): ReLU()\n",
       "    (LeakyReLU1): LeakyReLU(negative_slope=0.01)\n",
       "    (ELU3): ELU(alpha=1.0)\n",
       "    (LeakyReLU2): LeakyReLU(negative_slope=0.01)\n",
       "    (ELU4): ELU(alpha=1.0)\n",
       "    (LeakyReLU3): LeakyReLU(negative_slope=0.01)\n",
       "    (output): Linear(in_features=823, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is very clunky to use; find some way to have optimization function passed to fitnessevaluator (we generate nn twice otherwise)\n",
    "nn = NeuralNetwork(ind.genome, input_layer=(torch.nn.Linear, 28*28), output_layer=(torch.nn.Linear, 10))\n",
    "nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.genome.batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.genome.epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = FitnessEvaluator(ind, training_data, test_data, \n",
    "                        torch.nn.CrossEntropyLoss(), \n",
    "                        torch.optim.SGD(nn.model.to(ind.device).parameters(), lr=1e-3),\n",
    "                        ind.device,\n",
    "                        nn = nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303464  [   64/60000]\n",
      "loss: 2.298164  [ 6464/60000]\n",
      "loss: 2.303468  [12864/60000]\n",
      "loss: 2.302395  [19264/60000]\n",
      "loss: 2.306775  [25664/60000]\n",
      "loss: 2.303379  [32064/60000]\n",
      "loss: 2.303770  [38464/60000]\n",
      "loss: 2.300689  [44864/60000]\n",
      "loss: 2.303067  [51264/60000]\n",
      "loss: 2.305223  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 2.302714 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.302847  [   64/60000]\n",
      "loss: 2.298209  [ 6464/60000]\n",
      "loss: 2.303136  [12864/60000]\n",
      "loss: 2.302260  [19264/60000]\n",
      "loss: 2.306907  [25664/60000]\n",
      "loss: 2.303572  [32064/60000]\n",
      "loss: 2.302887  [38464/60000]\n",
      "loss: 2.301523  [44864/60000]\n",
      "loss: 2.303262  [51264/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m acc, loss \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:42\u001b[0m, in \u001b[0;36mFitnessEvaluator.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     43\u001b[0m     accuracy, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n\u001b[1;32m     44\u001b[0m     accuracy_series[t] \u001b[39m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:67\u001b[0m, in \u001b[0;36mFitnessEvaluator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     66\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m pred \u001b[39m=\u001b[39m nnet(X)\n\u001b[1;32m     68\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     70\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/neural_network.py:26\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     25\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[0;32m---> 26\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1364\u001b[0m, in \u001b[0;36mPReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1364\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mprelu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc, loss = eval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_params = EvolutionParameters(mutation_prob, crossover_prob,\n",
    "                                 training_data, test_data,\n",
    "                                 torch.nn.CrossEntropyLoss(),\n",
    "                                 lambda x: torch.optim.SGD(x, lr=1e-3),\n",
    "                                 input_layer=(torch.nn.Linear, 28*28),\n",
    "                                 output_layer=(torch.nn.Linear, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.293381  [   64/60000]\n",
      "loss: 2.299838  [ 6464/60000]\n",
      "loss: 2.309453  [12864/60000]\n",
      "loss: 2.301697  [19264/60000]\n",
      "loss: 2.307805  [25664/60000]\n",
      "loss: 2.307318  [32064/60000]\n",
      "loss: 2.296962  [38464/60000]\n",
      "loss: 2.310831  [44864/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ind \u001b[39m=\u001b[39m Individual(evo_params, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                             GenomeParameters(\u001b[39m#activation_functions=[torch.nn.Linear, torch.nn.ReLU],\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                              min_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, max_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                              min_hidden_neurons\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, max_hidden_neurons\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                              min_batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, max_batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                              ),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                             device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mvars\u001b[39m(ind\u001b[39m.\u001b[39mgenome)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/individual.py:21\u001b[0m, in \u001b[0;36mIndividual.__init__\u001b[0;34m(self, evolution_params, genome_params, device, genome)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenome_params \u001b[39m=\u001b[39m genome_params\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[0;32m---> 21\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeasure_fitness()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/individual.py:35\u001b[0m, in \u001b[0;36mIndividual.measure_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure_fitness\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Measure the fitness of the individual'''\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m FitnessEvaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevolution_params, \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:40\u001b[0m, in \u001b[0;36mFitnessEvaluator.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     41\u001b[0m     accuracy, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n\u001b[1;32m     42\u001b[0m     accuracy_series[t] \u001b[39m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:70\u001b[0m, in \u001b[0;36mFitnessEvaluator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[1;32m     69\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 70\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     71\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/optim/sgd.py:75\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     71\u001b[0m momentum_buffer_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m has_sparse_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001b[0;32m---> 75\u001b[0m sgd(params_with_grad,\n\u001b[1;32m     76\u001b[0m     d_p_list,\n\u001b[1;32m     77\u001b[0m     momentum_buffer_list,\n\u001b[1;32m     78\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     79\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     80\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     81\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     82\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     83\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     84\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m     85\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     87\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/optim/sgd.py:220\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 220\u001b[0m func(params,\n\u001b[1;32m    221\u001b[0m      d_p_list,\n\u001b[1;32m    222\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    224\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    225\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    226\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    227\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    228\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    229\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/optim/sgd.py:263\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[0;32m--> 263\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mlr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ind = Individual(evo_params, \n",
    "                            GenomeParameters(#activation_functions=[torch.nn.Linear, torch.nn.ReLU],\n",
    "                                             min_epochs=3, max_epochs=3,\n",
    "                                             min_hidden_neurons=256, max_hidden_neurons=1024,\n",
    "                                             min_batch_size=64, max_batch_size=64\n",
    "                                             ),\n",
    "                            device='mps')\n",
    "vars(ind.genome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.30282717, 2.30252329, 2.30227114]), array([0.1009, 0.1009, 0.1009]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.307581  [   16/60000]\n",
      "loss: 2.304007  [ 1616/60000]\n",
      "loss: 2.302469  [ 3216/60000]\n",
      "loss: 2.299960  [ 4816/60000]\n",
      "loss: 2.308159  [ 6416/60000]\n",
      "loss: 2.305856  [ 8016/60000]\n",
      "loss: 2.312680  [ 9616/60000]\n",
      "loss: 2.311811  [11216/60000]\n",
      "loss: 2.299243  [12816/60000]\n",
      "loss: 2.304780  [14416/60000]\n",
      "loss: 2.308098  [16016/60000]\n",
      "loss: 2.299286  [17616/60000]\n",
      "loss: 2.306631  [19216/60000]\n",
      "loss: 2.303165  [20816/60000]\n",
      "loss: 2.300147  [22416/60000]\n",
      "loss: 2.303380  [24016/60000]\n",
      "loss: 2.291083  [25616/60000]\n",
      "loss: 2.297090  [27216/60000]\n",
      "loss: 2.296386  [28816/60000]\n",
      "loss: 2.311637  [30416/60000]\n",
      "loss: 2.298645  [32016/60000]\n",
      "loss: 2.306671  [33616/60000]\n",
      "loss: 2.297541  [35216/60000]\n",
      "loss: 2.307045  [36816/60000]\n",
      "loss: 2.298802  [38416/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/tests.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ind\u001b[39m.\u001b[39;49mmeasure_fitness()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/individual.py:35\u001b[0m, in \u001b[0;36mIndividual.measure_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure_fitness\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Measure the fitness of the individual'''\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m FitnessEvaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevolution_params, \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:40\u001b[0m, in \u001b[0;36mFitnessEvaluator.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     41\u001b[0m     accuracy, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n\u001b[1;32m     42\u001b[0m     accuracy_series[t] \u001b[39m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/fitness.py:65\u001b[0m, in \u001b[0;36mFitnessEvaluator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     64\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m pred \u001b[39m=\u001b[39m nnet(X)\n\u001b[1;32m     66\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     68\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/neural_network.py:26\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     25\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[0;32m---> 26\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1364\u001b[0m, in \u001b[0;36mPReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1364\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mprelu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ind.measure_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = FitnessEvaluator(ind, E, \n",
    "                        torch.nn.CrossEntropyLoss(), \n",
    "                        torch.optim.SGD(nn.model.to(ind.device).parameters(), lr=1e-3),\n",
    "                        ind.device,\n",
    "                        nn = nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from individual import Individual\n",
    "from generation import Generation\n",
    "from evolution_parameters import EvolutionParameters\n",
    "from genome_parameters import GenomeParameters\n",
    "from neural_network import NeuralNetwork\n",
    "from fitness import FitnessEvaluator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_cnt = 4\n",
    "mutation_prob = 0.3\n",
    "crossover_prob = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.316954  [   28/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/Users/rderi/Programming/Class/COSC461-S24/cosc461_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.289083  [ 2828/60000]\n",
      "loss: 2.294587  [ 5628/60000]\n",
      "loss: 2.320787  [ 8428/60000]\n",
      "loss: 2.292530  [11228/60000]\n",
      "loss: 2.300985  [14028/60000]\n",
      "loss: 2.279706  [16828/60000]\n",
      "loss: 2.315766  [19628/60000]\n",
      "loss: 2.316736  [22428/60000]\n",
      "loss: 2.304193  [25228/60000]\n",
      "loss: 2.315670  [28028/60000]\n",
      "loss: 2.283728  [30828/60000]\n",
      "loss: 2.328009  [33628/60000]\n",
      "loss: 2.318639  [36428/60000]\n",
      "loss: 2.298093  [39228/60000]\n",
      "loss: 2.302464  [42028/60000]\n",
      "loss: 2.325456  [44828/60000]\n",
      "loss: 2.307033  [47628/60000]\n",
      "loss: 2.305549  [50428/60000]\n",
      "loss: 2.299368  [53228/60000]\n",
      "loss: 2.313679  [56028/60000]\n",
      "loss: 2.314768  [58828/60000]\n",
      "Test Error: \n",
      " Accuracy: 9.8%, Avg loss: 2.304891 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.344736  [    7/60000]\n",
      "loss: 2.225368  [  707/60000]\n",
      "loss: 2.268105  [ 1407/60000]\n",
      "loss: 2.353578  [ 2107/60000]\n",
      "loss: 2.394616  [ 2807/60000]\n",
      "loss: 2.217835  [ 3507/60000]\n",
      "loss: 2.267605  [ 4207/60000]\n",
      "loss: 2.181513  [ 4907/60000]\n",
      "loss: 2.467712  [ 5607/60000]\n",
      "loss: 2.251557  [ 6307/60000]\n",
      "loss: 2.284251  [ 7007/60000]\n",
      "loss: 2.348799  [ 7707/60000]\n",
      "loss: 2.331724  [ 8407/60000]\n",
      "loss: 2.283165  [ 9107/60000]\n",
      "loss: 2.331366  [ 9807/60000]\n",
      "loss: 2.325617  [10507/60000]\n",
      "loss: 2.244838  [11207/60000]\n",
      "loss: 2.235810  [11907/60000]\n",
      "loss: 2.340184  [12607/60000]\n",
      "loss: 2.328637  [13307/60000]\n",
      "loss: 2.305296  [14007/60000]\n",
      "loss: 2.345675  [14707/60000]\n",
      "loss: 2.343267  [15407/60000]\n",
      "loss: 2.254955  [16107/60000]\n",
      "loss: 2.197977  [16807/60000]\n",
      "loss: 2.334881  [17507/60000]\n",
      "loss: 2.295042  [18207/60000]\n",
      "loss: 2.294228  [18907/60000]\n",
      "loss: 2.367787  [19607/60000]\n",
      "loss: 2.252126  [20307/60000]\n",
      "loss: 2.318277  [21007/60000]\n",
      "loss: 2.169105  [21707/60000]\n",
      "loss: 2.278157  [22407/60000]\n",
      "loss: 2.334231  [23107/60000]\n",
      "loss: 2.278672  [23807/60000]\n",
      "loss: 2.234767  [24507/60000]\n",
      "loss: 2.252929  [25207/60000]\n",
      "loss: 2.262785  [25907/60000]\n",
      "loss: 2.238775  [26607/60000]\n",
      "loss: 2.225793  [27307/60000]\n",
      "loss: 2.264761  [28007/60000]\n",
      "loss: 2.301194  [28707/60000]\n",
      "loss: 2.281928  [29407/60000]\n",
      "loss: 2.273149  [30107/60000]\n",
      "loss: 2.268290  [30807/60000]\n",
      "loss: 2.348096  [31507/60000]\n",
      "loss: 2.307819  [32207/60000]\n",
      "loss: 2.305733  [32907/60000]\n",
      "loss: 2.305515  [33607/60000]\n",
      "loss: 2.283238  [34307/60000]\n",
      "loss: 2.208738  [35007/60000]\n",
      "loss: 2.321522  [35707/60000]\n",
      "loss: 2.302429  [36407/60000]\n",
      "loss: 2.248370  [37107/60000]\n",
      "loss: 2.293337  [37807/60000]\n",
      "loss: 2.242422  [38507/60000]\n",
      "loss: 2.292218  [39207/60000]\n",
      "loss: 2.317763  [39907/60000]\n",
      "loss: 2.240369  [40607/60000]\n",
      "loss: 2.284169  [41307/60000]\n",
      "loss: 2.227530  [42007/60000]\n",
      "loss: 2.270133  [42707/60000]\n",
      "loss: 2.254500  [43407/60000]\n",
      "loss: 2.315596  [44107/60000]\n",
      "loss: 2.275538  [44807/60000]\n",
      "loss: 2.289003  [45507/60000]\n",
      "loss: 2.256122  [46207/60000]\n",
      "loss: 2.302020  [46907/60000]\n",
      "loss: 2.270361  [47607/60000]\n",
      "loss: 2.237922  [48307/60000]\n",
      "loss: 2.280156  [49007/60000]\n",
      "loss: 2.288618  [49707/60000]\n",
      "loss: 2.267692  [50407/60000]\n",
      "loss: 2.277422  [51107/60000]\n",
      "loss: 2.263310  [51807/60000]\n",
      "loss: 2.245034  [52507/60000]\n",
      "loss: 2.297363  [53207/60000]\n",
      "loss: 2.263849  [53907/60000]\n",
      "loss: 2.256692  [54607/60000]\n",
      "loss: 2.277082  [55307/60000]\n",
      "loss: 2.278261  [56007/60000]\n",
      "loss: 2.275226  [56707/60000]\n",
      "loss: 2.257045  [57407/60000]\n",
      "loss: 2.277219  [58107/60000]\n",
      "loss: 2.295473  [58807/60000]\n",
      "loss: 2.283043  [59507/60000]\n",
      "Test Error: \n",
      " Accuracy: 25.1%, Avg loss: 2.262682 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.248916  [    7/60000]\n",
      "loss: 2.280709  [  707/60000]\n",
      "loss: 2.280102  [ 1407/60000]\n",
      "loss: 2.218869  [ 2107/60000]\n",
      "loss: 2.292550  [ 2807/60000]\n",
      "loss: 2.297791  [ 3507/60000]\n",
      "loss: 2.221332  [ 4207/60000]\n",
      "loss: 2.220401  [ 4907/60000]\n",
      "loss: 2.285825  [ 5607/60000]\n",
      "loss: 2.282807  [ 6307/60000]\n",
      "loss: 2.252264  [ 7007/60000]\n",
      "loss: 2.270552  [ 7707/60000]\n",
      "loss: 2.236246  [ 8407/60000]\n",
      "loss: 2.210982  [ 9107/60000]\n",
      "loss: 2.257221  [ 9807/60000]\n",
      "loss: 2.256745  [10507/60000]\n",
      "loss: 2.212741  [11207/60000]\n",
      "loss: 2.244966  [11907/60000]\n",
      "loss: 2.254009  [12607/60000]\n",
      "loss: 2.311631  [13307/60000]\n",
      "loss: 2.228415  [14007/60000]\n",
      "loss: 2.252442  [14707/60000]\n",
      "loss: 2.309436  [15407/60000]\n",
      "loss: 2.246452  [16107/60000]\n",
      "loss: 2.235614  [16807/60000]\n",
      "loss: 2.287112  [17507/60000]\n",
      "loss: 2.268077  [18207/60000]\n",
      "loss: 2.259248  [18907/60000]\n",
      "loss: 2.262853  [19607/60000]\n",
      "loss: 2.248268  [20307/60000]\n",
      "loss: 2.242358  [21007/60000]\n",
      "loss: 2.207961  [21707/60000]\n",
      "loss: 2.254018  [22407/60000]\n",
      "loss: 2.291898  [23107/60000]\n",
      "loss: 2.288582  [23807/60000]\n",
      "loss: 2.246685  [24507/60000]\n",
      "loss: 2.229930  [25207/60000]\n",
      "loss: 2.257113  [25907/60000]\n",
      "loss: 2.244571  [26607/60000]\n",
      "loss: 2.174205  [27307/60000]\n",
      "loss: 2.199724  [28007/60000]\n",
      "loss: 2.276577  [28707/60000]\n",
      "loss: 2.217728  [29407/60000]\n",
      "loss: 2.174426  [30107/60000]\n",
      "loss: 2.235474  [30807/60000]\n",
      "loss: 2.261578  [31507/60000]\n",
      "loss: 2.258116  [32207/60000]\n",
      "loss: 2.228188  [32907/60000]\n",
      "loss: 2.250582  [33607/60000]\n",
      "loss: 2.246422  [34307/60000]\n",
      "loss: 2.139671  [35007/60000]\n",
      "loss: 2.228151  [35707/60000]\n",
      "loss: 2.244460  [36407/60000]\n",
      "loss: 2.178090  [37107/60000]\n",
      "loss: 2.238899  [37807/60000]\n",
      "loss: 2.213990  [38507/60000]\n",
      "loss: 2.216984  [39207/60000]\n",
      "loss: 2.216220  [39907/60000]\n",
      "loss: 2.187038  [40607/60000]\n",
      "loss: 2.240644  [41307/60000]\n",
      "loss: 2.118385  [42007/60000]\n",
      "loss: 2.202112  [42707/60000]\n",
      "loss: 2.182029  [43407/60000]\n",
      "loss: 2.266745  [44107/60000]\n",
      "loss: 2.238802  [44807/60000]\n",
      "loss: 2.205755  [45507/60000]\n",
      "loss: 2.209070  [46207/60000]\n",
      "loss: 2.219819  [46907/60000]\n",
      "loss: 2.211344  [47607/60000]\n",
      "loss: 2.122859  [48307/60000]\n",
      "loss: 2.201772  [49007/60000]\n",
      "loss: 2.237473  [49707/60000]\n",
      "loss: 2.160607  [50407/60000]\n",
      "loss: 2.219525  [51107/60000]\n",
      "loss: 2.214481  [51807/60000]\n",
      "loss: 2.132087  [52507/60000]\n",
      "loss: 2.217282  [53207/60000]\n",
      "loss: 2.179015  [53907/60000]\n",
      "loss: 2.133651  [54607/60000]\n",
      "loss: 2.155816  [55307/60000]\n",
      "loss: 2.180742  [56007/60000]\n",
      "loss: 2.208416  [56707/60000]\n",
      "loss: 2.156841  [57407/60000]\n",
      "loss: 2.214058  [58107/60000]\n",
      "loss: 2.210129  [58807/60000]\n",
      "loss: 2.207998  [59507/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.158687 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306797  [   96/60000]\n",
      "loss: 2.304281  [ 9696/60000]\n",
      "loss: 2.311907  [19296/60000]\n",
      "loss: 2.290799  [28896/60000]\n",
      "loss: 2.278321  [38496/60000]\n",
      "loss: 2.295766  [48096/60000]\n",
      "loss: 2.288329  [57696/60000]\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 2.280648 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298839  [   95/60000]\n",
      "loss: 2.300884  [ 9595/60000]\n",
      "loss: 2.295551  [19095/60000]\n",
      "loss: 2.293491  [28595/60000]\n",
      "loss: 2.315904  [38095/60000]\n",
      "loss: 2.318686  [47595/60000]\n",
      "loss: 2.314344  [57095/60000]\n",
      "Test Error: \n",
      " Accuracy: 9.8%, Avg loss: 2.309838 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.298085  [   95/60000]\n",
      "loss: 2.300345  [ 9595/60000]\n",
      "loss: 2.295441  [19095/60000]\n",
      "loss: 2.293070  [28595/60000]\n",
      "loss: 2.314380  [38095/60000]\n",
      "loss: 2.316809  [47595/60000]\n",
      "loss: 2.313174  [57095/60000]\n",
      "Test Error: \n",
      " Accuracy: 9.8%, Avg loss: 2.308716 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation = Generation(population_cnt, \n",
    "                 EvolutionParameters(mutation_prob, crossover_prob,\n",
    "                                     training_data, test_data,\n",
    "                                     torch.nn.CrossEntropyLoss(),\n",
    "                                     lambda x: torch.optim.SGD(x, lr=1e-3),\n",
    "                                     tournament_size=2,\n",
    "                                     input_layer=(torch.nn.Linear, 28*28),\n",
    "                                     output_layer=(torch.nn.Linear, 10)), \n",
    "                 GenomeParameters(max_hidden_layers=10, max_epochs=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation.progress_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generation.population)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
